I am **Xiangtai Li**, I work on computer vision, multi-modal learning and related problems.

I am working as a **Research Scientist** in Bytedance Seed (Tiktok), Singapore, working on multi-modal large langauge models, including both products and related research.

Previously, I worked as a **Research Fellow** at [MMLab@NTU](https://www.mmlab-ntu.com/), S-Lab advised by [Prof.Chen Change Loy](https://www.mmlab-ntu.com/person/ccloy/).

I obtained my PhD degree at Peking University (PKU) under the supervision of [Prof.Yunhai Tong](https://scholar.google.com/citations?user=T4gqdPkAAAAJ&hl=zh-CN), and my bachelor's degree at Beijing University of Posts and Telecommunications (BUPT).

Previously, I worked as research intern or research scientist in DeepMotion (Now Xiaomi Car) / JD Exploration Academy / Sensetime Research / Shanghai AI Laboratory / Skywork 2050 Research, with several research outputs on top conference and journals. 

My research topics are:

Multi-modal learning with LLMs (MLLM): Benchmarking, new architecture design, unified modeling.

Large language models (LLM) and auto-regressive model.

Image/video generation, editing and synthesis. (Diffusion Models)


Previously, I did some works on image/video segmentation and detection, open vocabulary learning.

Moreover, the code and models for my works (maybe 98%), including the ones I have deeply contributed to, are open-sourced on [GitHub](https://github.com/lxtGH).

I serve as a regular reviewer for lots of conference and journals, including CVPR, ICCV, ECCV, ICLR, AAAI, NeurIPS, ICML, IJCAI, IEEE-TIP, IEEE-TPAMI, IJCV, IEEE-TSCVT, IEEE-TMM, IEEE-TGRS, Remote Sensing.

I also serve as an area chair for ICLR-2025, ICML-2025, ICCV-2025, NeurIPS-2025.