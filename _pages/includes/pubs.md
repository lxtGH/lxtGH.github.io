# üìù Publications  


\* means equal contribution.


[//]: # (Full Publications Per Year can be found in [Here]&#40;../project/pub&#41;.)

## Top-5 My Favourite Works


<li><a href="https://arxiv.org/abs/2401.10229">OMG-Seg: Is One Model Good Enough For All Segmentation?</a>,  
     <strong>Xiangtai Li</strong>, Haobo Yuan, Wei Li, Henghui Ding, Size Wu, Wenwei Zhang, Yining Li, Kai Chen, Chen Change Loy
      <strong>CVPR 2024 <span style="color:red"> One model to perform image/video/open-vocabulary/multi-dataset/interactive segmentation in one shot. </span> </strong> | <a href=" https://lxtgh.github.io/project/omg_seg/">Project Page</a> </li>


<li><a href="https://arxiv.org/abs/2204.04656">Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation</a>,  
      <strong>Xiangtai Li*</strong>, Wenwei Zhang*, Jiangmiao Pang*, Kai Chen, Guangliang Cheng, Yunhai Tong, Chen Change Loy,
      <strong>CVPR 2022 <span style="color:red">(Oral, top2%) The first unified video segmentation model and codebase for VPS, VIS, VSS</span> </strong> | <a href="https://github.com/lxtGH/Video-K-Net">Code</a> </li>


<li><a href="https://arxiv.org/abs/2303.12782">Tube-Link: A Flexible Cross Tube Baseline for Universal Video Segmentation</a>,  
      <strong>Xiangtai Li</strong>, Haobo Yuan, Wenwei Zhang, Guangliang Cheng, Jiangmiao Pang, Chen Change Loy,
      <strong>ICCV 2023 <span style="color:red"> The first unified SOTA universal video segmentation model. </span> </strong> | <a href="https://github.com/lxtGH/Tube-Link">Project</a> </li>


<li><a href="https://arxiv.org/abs/2002.10120">Semantic Flow for Fast and Accurate Scene Parsing</a>,  
      <strong>Xiangtai Li</strong>, Ansheng You, Zhen Zhu, Houlong Zhao, Maoke Yang, Kuiyuan Yang, Yunhai Tong,
      <strong>ECCV 2020 <span style="color:red">(Oral, top2%) The first real-time model over 80% mIoU on Cityscapes test set.</span></strong> | <a href="https://github.com/lxtGH/SFSegNets">Code</a> </li>


<li><a href="https://arxiv.org/abs/2201.05047"> TransVOD: End-to-end Video Object Detection with Spatial-Temporal Transformers </a>,  
    Qianyu Zhou*,  <strong> Xiangtai Li* </strong>, Lu He, Yibo Yang, Guangliang Cheng, Yunhai Tong, Lizhuang Ma, Dacheng Tao,
      <strong>T-PAMI-2022 <span style="color:red"> The first End-to-End Vision Transformer for Video Object Detection and STOA results on Video Object Detection </span> </strong> | <a href="https://github.com/SJTU-LuHe/TransVOD">Code</a> </li>



## Several Recent Arxiv Works

<li><a href="https://arxiv.org/abs/2405.17427"> Reason3D: Searching and Reasoning 3D Segmentation via Large Language Model </a>,  
    Kuan-Chih Huang,  <strong> Xiangtai Li </strong>, Lu Qi, Shuicheng Yan, Ming-Hsuan Yang,
      <strong>Arxiv-2024 <span style="color:red"> LLM meets 3D reasoning segmentation </span> </strong> | <a href="https://KuanchihHuang.github.io/project/reason3d">Code</a> </li>

<li><a href="https://arxiv.org/abs/2405.20282"> SemFlow: Binding Semantic Segmentation and Image Synthesis via Rectified Flow </a>,  
    Chaoyang Wang,  <strong> Xiangtai Li </strong>, Lu Qi, Henghui Ding, Yunhai Tong, Ming-Hsuan Yang,
      <strong>Arxiv-2024 <span style="color:red"> Binding Semantic Segmentation and Synthesis using LDM and Rectified Flow </span> </strong> | <a href="https://github.com/wang-chaoyang/SemFlow">Code</a> </li>

<li><a href="https://arxiv.org/abs/2404.00086"> DVIS-DAQ: Improving Video Segmentation via Dynamic Anchor Queries </a>,  
       Yikang Zhou, Tao Zhang, Shunping Ji, Shuicheng Yan, <strong> Xiangtai Li </strong>,
      <strong>Arxiv-2024 <span style="color:red"> Dynamic anchor query design for long and complex video segmentation </span> </strong> | <a href="https://github.com/SkyworkAI/DAQ-VS">Code</a> </li>

<li><a href="https://arxiv.org/abs/2402.02555"> Generalizable Entity Grounding via Assistance of Large Language Model</a>,  
   Lu Qi, Yi-Wen Chen, Lehan Yang, Tiancheng Shen, <strong>Xiangtai Li</strong>, Weidong Guo, Yu Xu, Ming-Hsuan Yang,
      <strong>Arxiv-2024 <span style="color:red"> Add LLM with entity-level segmentation and grounding </span> </strong> | <a href="">Code</a> </li>

<li><a href="https://arxiv.org/abs/2403.00762"> Point Cloud Mamba: Point Cloud Learning via State Space Model </a>,  
   Tao Zhang,  <strong>Xiangtai Li </strong>, Haobo Yuan, Shunping Ji, Shuicheng Yan,
    <strong>Arxiv-2024 <span style="color:red"> Mamba-like point cloud model that outperform Transformers and MLP on both efficiency and accuracy. </span> </strong> | <a href="https://github.com/SkyworkAI/PointCloudMamba">Code</a> </li>


Code can be found in [this](https://github.com/lxtGH).

Full publication can be found in [Google Scholar](https://scholar.google.com/citations?user=FL3ReD0AAAAJ&hl=zh-CN)