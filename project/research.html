
<!DOCTYPE HTML>
<html lang="en">

<body>
  <table id="container">
    <tr>
      <td>

        <table width="130%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                </ol>
                <heading>2022</heading>
                <ol>
                  <li>
                    <a href="https://arxiv.org/abs/2208.13721">
                    <papertitle>Turbo Training with Token Dropout.</papertitle>
                    </a>
                    <br>
                    Tengda Han, <strong>Weidi Xie</strong>, Andrew Zisserman
                    <br> 
                    In: <em>British Machine Vision Conference (BMVC) </em>, 2022. <br>
                    <a href="">Project Page</a> |
                    <a href="https://arxiv.org/abs/2210.04889">Arxiv</a>
                    </li>
                <p> </p>   

                <li>
                  <a href="https://arxiv.org/abs/2208.13721">
                  <papertitle>A Simple Plugin for Transforming Images to Arbitrary Scales.</papertitle>
                  </a>
                  <br>
                  Qinye Zhou, Ziyi Li, <strong>Weidi Xie^&dagger;</strong>, Xiaoyun Zhang, Ya Zhang, Yanfeng Wang&dagger;
                  <br> 
                  In: <em>British Machine Vision Conference (BMVC) </em>, 2022. <br>
                  <a href="https://lipurple.github.io/ARIS_Webpage/">Project Page</a> |
                  <a href="https://arxiv.org/abs/2210.03417">Arxiv</a>
                  </li>
              <p> </p>  
              
              <li>
                <a href="https://arxiv.org/abs/2210.07055">
                <papertitle>Sparse in Space and Time: Audio-visual Synchronisation with Trainable Selectors.</papertitle>
                </a>
                <br>
                Vladimir Iashin, <strong>Weidi Xie</strong>, Esa Rahtu, Andrew Zisserman
                <br> 
                In: <em>British Machine Vision Conference (BMVC) </em>, 2022. &nbsp <font color="red"><strong>(Spotlight)</strong></font> 
                <br> 
                <a href="http://v-iashin.github.io/SparseSync">Project Page</a> |
                <a href="https://arxiv.org/abs/2210.07055">Arxiv</a>
                </li>
            <p> </p>   

                <li>
                    <a href="https://arxiv.org/abs/2208.13721">
                    <papertitle>CounTR: Transformer-based Generalised Visual Counting.</papertitle>
                    </a>
                    <br>
                    Chang Liu, Yujie Zhong, Andrew Zisserman, <strong>Weidi Xie</strong>
                    <br> 
                    In: <em>British Machine Vision Conference (BMVC) </em>, 2022. <br>
                    <a href="https://verg-avesta.github.io/CounTR_Webpage/">Project Page</a> |
                    <a href="https://arxiv.org/abs/2208.13721">Arxiv</a>
                    </li>
                <p> </p>   

                <li>
                  <a href="https://arxiv.org/pdf/2206.06947">
                  <papertitle>K-Space Transformer for Fast MRI Reconstruction.</papertitle>
                  </a>
                  <br>
                  Ziheng Zhao, Tianjiao Zhang, <strong>Weidi Xie&dagger;</strong>, Yanfeng Wang&dagger;, Ya Zhang
                  <br>
                  In: <em>British Machine Vision Conference (BMVC) </em>, 2022. <br>
                  <a href="https://zhaoziheng.github.io/Website/K-Space-Transformer">Project Page</a> |
                  <a href="https://arxiv.org/pdf/2206.06947">Arxiv</a>
                  </li>
                  <p> </p>  

                  <li>
                    <a href="">
                    <papertitle>Open-vocabulary Semantic Segmentation with Frozen Vision-Language Models.</papertitle>
                    </a>
                    <br>
                    Chaofan Ma, Yuhuan Yang, Yanfeng Wang, Ya Zhang, <strong>Weidi Xie</strong>
                    <br>
                    In: <em>British Machine Vision Conference (BMVC) </em>, 2022. &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> 
                    <br> 
                    <a href="">Project Page</a> |
                    <a href="">Arxiv</a>
                    </li>
                    <p> </p>  

                   <li>
                    <a href="https://omnimatte-sp.github.io">
                    <papertitle>Associating Objects and Their Effects in Video through Coordination Games.</papertitle>
                    </a>
                    <br>
                    Erika Lu, Forrester Cole, <strong>Weidi Xie</strong>, Tali Dekel, William T. Freeman, Andrew Zisserman, Michael Rubinstein
                    <br> 
                    In: <em>Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS) </em>, 2022. <br>
                    <a href="https://omnimatte-sp.github.io">Project Page</a> |
                    <a href="https://openreview.net/pdf?id=hq-p55-qil9">Paper</a>
                    </li>
                <p> </p>  

                <li>
                  <a href="https://arxiv.org/abs/2206.07045">
                  <papertitle>ReCo: Retrieve and Co-segment for Zero-shot Transfer.</papertitle>
                  </a>
                  <br>
                  Gyungin Shin, <strong>Weidi Xie</strong>, Samuel Albanie
                  <br> 
                  In: <em>Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS) </em>, 2022. <br>
                  <a href="https://www.robots.ox.ac.uk/~vgg/research/reco/">Project Page</a> |
                  <a href="https://arxiv.org/abs/2206.07045">Arxiv</a>
                  </li>
              <p> </p>  

                <li>
                    <a href="https://arxiv.org/abs/2207.02206">
                    <papertitle>Segmenting Moving Objects via an Object-Centric Layered Representation.</papertitle>
                    </a>
                    <br>
                    Junyu Xie, <strong>Weidi Xie</strong>, Andrew Zisserman
                    <br> 
                    In: <em>Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS) </em>, 2022. <br>
                    <a href="">Project Page</a> |
                    <a href="https://arxiv.org/abs/2207.02206">Arxiv</a>
                    </li>
                <p> </p>   

                <li>
                    <a href="https://ju-chen.github.io/efficient-prompt/">
                    <papertitle>Prompting Visual-Language Models for Efficient Video Understanding.</papertitle>
                    </a>
                    <br>
                    Chen Ju, Tengda Han, Kunhao Zheng, Ya Zhang, <strong>Weidi Xie</strong>
                    <br>
                    In: <em>European Conference on Computer Vision (ECCV) </em>, 2022
                    <br> 
                    <a href="https://ju-chen.github.io/efficient-prompt/">Project Page</a> |
                    <a href="https://arxiv.org/pdf/2112.04478.pdf">Arxiv</a>
                    </li>
                <p> </p>   

                <li>
                  <a href="https://arxiv.org/abs/2203.16513">
                  <papertitle>PromptDet: Expand Your Detector Vocabulary with Uncurated Images.</papertitle>
                  </a>
                  <br>
                  Chengjian Feng, Yujie Zhong, Zequn Jie, Xiangxiang Chu, Haibing Ren, Xiaolin Wei, <strong>Weidi Xie&dagger;</strong>, Lin Ma
                  <br>
                  In: <em>European Conference on Computer Vision (ECCV) </em>, 2022
                  <br> 
                  <a href="https://fcjian.github.io/promptdet">Project Page</a> |
                  <a href="https://arxiv.org/abs/2203.16513">Arxiv</a> 
                  </li>
                  <p> </p>

                  <li>
                    <a href="https://arxiv.org/abs/2206.12772">
                    <papertitle>Exploiting Transformation Invariance and Equivariance for Self-supervised Sound Localisation.</papertitle>
                    </a>
                    <br>
                    Jinxiang Liu, Chen Ju, <strong>Weidi Xie</strong>, Ya Zhang
                    <br>
                    In: <em>ACM Multimedia </em>, 2022.
                    <br> 
                    <a href="">Project Page</a> | <a href="https://arxiv.org/abs/2206.12772">Arxiv</a>
                    </li>
                    <p> </p> 
                  
                    <li>
                      <a href="">
                      <papertitle>Adaptive 3D Localization of 2D Freehand Ultrasound Brain Images.</papertitle>
                      </a>
                      <br>
                      Pak-Hei Yeung, Moska Aliasi, Monique Haak, the INTERGROWTH-21, <strong>Weidi Xie</strong>, Ana I.L. Namburete
                      <br>
                      In: <em> International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2022.
                      <br>
                      <a href="">Project Page</a> |
                      <a href="">Arxiv</a>
                      </li>
                    <p> </p>

                  <li>
                      <a href="">
                      <papertitle>Transforming the Interactive Segmentation for Medical Imaging.</papertitle>
                      </a>
                      <br>
                      Wentao Liu, Chaofan Ma, Yuhuan Yang, <strong>Weidi Xie</strong>, Ya Zhang
                      <br>
                      In: <em> International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2022.  &nbsp <font color="red"><strong>(Early Accept)</strong></font> 
                      <br>
                      <a href="https://wtliu7.github.io/tis/">Project Page</a> |
                      <a href="https://arxiv.org/abs/2208.09592">Arxiv</a>
                      </li>
                    <p> </p>  

                  <li>
                    <a href="https://arxiv.org/abs/2204.02968">
                    <papertitle>Temporal Alignment Networks for Long-term Video.</papertitle>
                    </a>
                    <br>
                    Tengda Han, <strong>Weidi Xie</strong>, Andrew Zisserman
                    <br>
                    In: <em>Conference on Computer Vision and Pattern Recognition (CVPR) </em>, 2022. &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> 
                    <br> 
                    <a href="https://www.robots.ox.ac.uk/~vgg/research/tan/">Project Page</a> | <a href="https://arxiv.org/abs/2204.02968">Arxiv</a>
                    </li>
                    <p> </p>            
                
                <li>
                    <a href="https://arxiv.org/abs/2112.05749v1">
                    <papertitle>Label, Verify, Correct: A Simple Few Shot Object Detection Method.</papertitle>
                    </a>
                    <br>
                    Prannay Kaul, <strong>Weidi Xie</strong>, Andrew Zisserman
                    <br>
                    In: <em>Conference on Computer Vision and Pattern Recognition (CVPR) </em>, 2022.
                    <br>
                    <a href="https://www.robots.ox.ac.uk/~vgg/research/lvc/">Project Page</a> |
                    <a href="https://arxiv.org/abs/2112.05749v1">Arxiv</a>
                    </li>
                  <p> </p>        

               <li>
                    <a href="https://charigyang.github.io/abouttime/">
                    <papertitle>It's About Time: Analog Clock Reading in the Wild.</papertitle>
                    </a>
                    <br>
                    Charig Yang, <strong>Weidi Xie</strong>, Andrew Zisserman
                    <br>
                    In: <em>Conference on Computer Vision and Pattern Recognition (CVPR) </em>, 2022.
                    <br>
                    <a href="https://charigyang.github.io/abouttime/">Project Page</a> |
                    <a href="https://arxiv.org/abs/2111.09162">Arxiv</a>
                    </li>
                  <p> </p>  
                    
                <li>
                    <a href="https://arxiv.org/pdf/2203.12614.pdf">
                    <papertitle>Unsupervised Salient Object Detection with Spectral Cluster Voting.</papertitle>
                    </a>
                    <br>
                    Gyungin Shin, Samuel Albanie, <strong>Weidi Xie</strong>
                    <br>
                    In: <em>Conference on Computer Vision and Pattern Recognition,  L3D-IVU Workshop </em>, 2022.
                    <br>
                    <a href="https://github.com/NoelShin/selfmask">Code</a> |
                    <a href="https://arxiv.org/pdf/2203.12614.pdf">Arxiv</a>
                    </li>
                    <p> </p>
                    
                </li>
                    <p> </p>
                    <li>
                    <a href="https://arxiv.org/abs/2103.14653">
                    <papertitle>Quantum Self-supervised Learning.</papertitle>
                    </a>
                    <br>
                        Ben Jaderberg, Lewis W. Anderson, <strong>Weidi Xie</strong>, Samuel Albanie, Martin Kiffner, Dieter Jaksch
                    <br>
                        In: <em>Quantum Science and Technology, 2022 (Impact Factor: ~5.2)</em>
                    <br>
                    <a href="https://github.com/bjader/quantum-neural-network">Code</a> |
                    <a href="https://arxiv.org/abs/2103.14653">Arxiv</a>
                    </li>
                    <p> </p>

                  <li>
                     <a href="https://arxiv.org/abs/2109.03230">
                     <papertitle>Self-supervised Tumor Segmentation through Layer Decomposition.</papertitle>
                     </a>
                     <br>
                     Xiaoman Zhang, <strong>Weidi Xie</strong>, Chaoqin Huang, Ya Zhang, Yanfeng Wang
                     <br>
                     <a href="https://xiaoman-zhang.github.io/Layer-Decomposition/">Project Page</a> |
                     <a href="https://arxiv.org/abs/2109.03230">Arxiv</a>
                     </li>
                     <p> </p>

                    <li>
                      <a href="https://www.sciencedirect.com/science/article/pii/S1053811922002452">
                      <papertitle>Subcortical Segmentation Of The Fetal Brain in 3D Ultrasound Using Deep Learning.</papertitle>
                      </a>
                      <br>
                      Linde S.Hesse, Moska Aliasi, Felipe Moser, the INTERGROWTH-21st Consortium, Monique C. Haak, <strong>Weidi Xie</strong>, Mark Jenkinson, Ana I.L. Namburete
                      <br>
                      In: <em>NeuroImage</em>, Volume 254, July, 2022. (Impact Factor: ~6.5) <br>
                      <a href="https://www.sciencedirect.com/science/article/pii/S1053811922002452">Link</a>
                      </li>
                      <p> </p>
                  
                  
                  
                </ol>
                <heading>2021</heading>
                <ol>
                  <li>
                    <a href="https://arxiv.org/abs/2109.12108">
                    <papertitle>ImplicitVol: Sensorless 3D Ultrasound Reconstruction with Deep Implicit Representation.</papertitle>
                    </a>
                    <br>
                      Pak-Hei Yeung, Linde Hesse, Moska Aliasi, Monique Haak, the INTERGROWTH-21st Consortium, <strong>Weidi Xie</strong>*, Ana I.L. Namburete*
                    <br>
                     <a href="https://pakheiyeung.github.io/ImplicitVol_wp/">Project Page</a> |
                    <a href="https://arxiv.org/abs/2109.12108">Arxiv</a>
                    </li>
                    <p> </p>
  
                  <li>
                    <a href="https://www.robots.ox.ac.uk/~vgg/publications/2021/Lamdouar21/lamdouar21.pdf">
                    <papertitle>Segmenting Invisible Moving Objects.</papertitle>
                    </a>
                    <br>
                      Hala Lamdouar,  <strong>Weidi Xie</strong>, Andrew Zisserman
                    <br>
                      In: <em> British Machine Vision Conference (BMVC)</em>, 2021.
                    <br>
                    <a href="https://www.robots.ox.ac.uk/~vgg/research/simo/">Project Page</a> |
                    <a href="paper/bmvc2021-motion segmentation.pdf">Paper</a>
                    <p> </p>

                  <li>
                    <a href="https://www.robots.ox.ac.uk/~vgg/publications/2021/Chen21b/chen21b.pdf">
                    <papertitle>Audio-Visual Synchronisation In the Wild.</papertitle>
                    </a>
                    <br>
                      Honglie Chen,  <strong>Weidi Xie</strong>, Triantafyllos Afouras, Arsha Nagrani, Andrea Vedaldi, Andrew Zisserman
                     <br>
                       In: <em> British Machine Vision Conference (BMVC)</em>, 2021.
                    <br>
                    <a href="https://www.robots.ox.ac.uk/~vgg/ research/avs">Project Page</a> |
                    <a href="paper/bmvc2021-audio-visual sync.pdf">Paper</a>
                    <p> </p>

                  <li>
                    <a href="https://arxiv.org/abs/2104.06394">
                    <papertitle>All You Need Are a Few Pixels: Semantic Segmentation with PixelPick.</papertitle>
                    </a>
                    <br>
                      Gyungin Shin,  <strong>Weidi Xie</strong>, Samuel Albanie
                    <br>
                      In: <em> International Conference on Computer Vision (ICCV),
                      <a href="https://ildav-workshop.github.io"> ILDAV Workshop</a> </em>, 2021. &nbsp <font color="red"><strong>(Best Paper Award)</strong></font>
                    <br>
                    <a href="https://www.robots.ox.ac.uk/~vgg/research/pixelpick/">Project Page</a> |
                    <a href="https://arxiv.org/abs/2104.06394">Arxiv</a>
                    <p> </p>

                  <li>
                    <a href="https://arxiv.org/abs/2102.07064">
                    <papertitle>NeRF--: Neural Radiance Fields Without Known Camera Parameters.</papertitle>
                    </a>
                    <br>
                      Zirui Wang, Shangzhe Wu,  <strong>Weidi Xie</strong>, Min Chen, Victor Adrian Prisacariu
                    <br>
                    <a href="https://nerfmm.active.vision">Project Page</a> |
                    <a href="https://arxiv.org/abs/2102.07064">Arxiv</a>
                    <p> </p>

                  <li>
                    <a href="https://arxiv.org/abs/2104.07658">
                    <papertitle>Self-supervised Video Object Segmentation by Motion Grouping.</papertitle>
                    </a>
                    <br>
                      Charig Yang, Hala Lamdouar, Erika Lu, Andrew Zisserman, <strong>Weidi Xie</strong>
                    <br>
                      In: <em> International Conference on Computer Vision (ICCV)</em>, 2021.
                    <br>
                      <a href="https://charigyang.github.io/motiongroup/">Project Page</a> |
                      <a href="https://arxiv.org/abs/2104.07658">Arxiv</a>
                    <p> </p>

                  <li>
                    <a href="https://arxiv.org/abs/2105.12722">
                    <papertitle>Sli2Vol: Annotate a 3D Volume from a Single Slice with Self-Supervised Learning.</papertitle>
                    </a>
                    <br>
                      Pak Hei Yeung, Ana I.L. Namburete, <strong>Weidi Xie</strong>
                    <br>
                      In: <em> International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2021.
                    <br>
                      <a href="https://pakheiyeung.github.io/Sli2Vol_wp/">Project Page</a> |
                      <a href="https://arxiv.org/abs/2105.12722">Arxiv</a>
                    <p> </p>

                  <li>
                    <a href="https://arxiv.org/abs/2104.07658">
                    <papertitle>Self-supervised Video Object Segmentation by Motion Grouping (Short Version).</papertitle>
                    </a>
                    <br>
                      Charig Yang, Hala Lamdouar, Erika Lu, Andrew Zisserman, <strong>Weidi Xie</strong>
                    <br>
                      In: <em>Conference on Computer Vision and Pattern Recognition (CVPR),
                      <a href="https://eval.vision.rwth-aachen.de/rvsu-workshop21/"> RVSU Workshop</a> </em>, 2021.
                      &nbsp <font color="red"><strong>(Best Paper Award)</strong></font>
                      <br>
                      <a href="https://charigyang.github.io/motiongroup/">Project Page</a> |
                      <a href="https://arxiv.org/abs/2104.07658">Arxiv</a>
                    <p> </p>

                  <li>
                    <a href="https://arxiv.org/abs/2104.02691">
                    <papertitle>Localizing Visual Sounds the Hard Way.</papertitle></a>
                    <br>
                    Honglie Chen, <b>Weidi Xie</b>, Triantafyllos Afouras, Arsha Nagrani, Andrea Vedaldi, Andrew Zisserman
                    <br>
                    In: <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2021
                    <br>
                    <a href="https://www.robots.ox.ac.uk/~vgg/research/lvs/">Project Page</a> |
                    <a href="https://arxiv.org/abs/2104.02691">Arxiv</a> </li>
                    <p> </p>

                  <li>
                    <a href="https://www.sciencedirect.com/science/article/pii/S136184152100044X#!">
                    <papertitle>Learning to Map 2D Ultrasound Images into 3D Space with Minimal Human Annotation.</papertitle></a>
                    <br>
                    Pak-Hei Yeung, Moska Aliasi, Aris T. Papageorghiou, Monique Haak, <b>Weidi Xie</b>, Ana I.L. Namburete.
                    <br>
                    In: <em>Medical Image Analysis, February 2021. (Impact Factor: ~14)</em>
                   <br>
                    <a href="https://pakheiyeung.github.io/PlaneInVol_wp/">Project Page</a> |
                    <a href="https://www.sciencedirect.com/science/article/pii/S136184152100044X#!">Paper</a> </li>
                    <p> </p>

                </ol>
                <heading>2020</heading>
                <ol>
                  <li>
                    <a href="https://arxiv.org/pdf/2012.06867.pdf">
                    <papertitle>VoxSRC 2020: The Second VoxCeleb Speaker Recognition Challenge.</papertitle>
                    </a>
                    <br>
                    Arsha Nagrani,
                    Joon Son Chung,
                    Jaesung Huh,
                    Andrew Brown,
                    Ernesto Coto,
                    <strong>Weidi Xie</strong>,
                    Mitchell McLaren,
                    Douglas A Reynolds,
                    Andrew Zisserman.<br>
                    <a href="https://www.sciencedirect.com/science/article/pii/S136184152100044X#!"> Tech Report</a></li>
                    <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/2010.09709">
                  <papertitle>Self-supervised Co-training for Video Representation Learning.</papertitle>
                  </a>
                  <br>
                  Tengda Han,
                  <strong>Weidi Xie</strong>, Andrew Zisserman <br>
                  In: <em>Thirty-fourth Conference on Neural Information Processing Systems (NeurIPS) </em>, 2020. <br>
                  <a href="https://arxiv.org/abs/2010.09709">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/research/CoCLR/">Project Page</a> |
                  <a href="https://github.com/TengdaHan/CoCLR">Code & Model</a></li>
                  <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/2011.11630">
                  <papertitle>Betrayed by Motion: Camouflaged Object Discovery via Motion Segmentation.</papertitle>
                  </a>
                  <br>
                  Hala Lamdouar, Charig Yang, <strong>Weidi Xie</strong>, Andrew Zisserman<br>
                  In: <em>Asian Conference on Computer Vision (ACCV)</em>, 2020. <br>
                  <a href="https://arxiv.org/abs/2011.11630">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2020/Lamdouar20/lamdouar20.pdf">PDF</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/data/MoCA/">Project Page</a></li>
                  <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/2009.07833">
                  <papertitle>Layered Neural Rendering for Retiming People in Video.</papertitle>
                  </a>
                  <br>
                  Erika Lu, Forrester Cole, Tali Dekel, <strong>Weidi Xie</strong>, Andrew Zisserman, David Salesin, William T. Freeman, Michael Rubinstein<br>
                  In: <em>ACM Transactions on Graphics (TOG). Proc. SIGGRAPH Asia </em>, 2020<br>

                  <a href="https://arxiv.org/abs/2009.07833">Arxiv</a> |
                  <a href="https://retiming.github.io">Project Page</a></li>
                  <p> </p>

                  <li>
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2020/Xie20/xie20.pdf">
                  <papertitle>Inducing Predictive Uncertainty Estimation for Face Recognition.</papertitle>
                  </a>
                  <br>
                  <strong>Weidi Xie</strong>, Jeffrey Byrne, Andrew Zisserman<br>
                  In: <em>British Machine Vision Conference (BMVC) </em>, 2020<br>
                  <a href="https://arxiv.org/abs/2009.00603">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2020/Xie20/xie20.pdf">PDF</a></li>
                  <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/2007.12163">
                  <papertitle>Smooth-AP: Smoothing the Path Towards Large-Scale Image Retrieval.</papertitle>
                  </a>
                  <br>
                  Andrew Brown, <strong>Weidi Xie</strong>, Vicky Kalogeiton, Andrew Zisserman<br>
                  In: <em>European Conference on Computer Vision (ECCV) </em>, 2020<br>
                   <a href="https://arxiv.org/abs/2007.12163">Arxiv</a> |
                   <a href="https://www.robots.ox.ac.uk/~vgg/research/smooth-ap/">Project Page</a> |
                  <a href="https://github.com/Andrew-Brown1/Smooth_AP">Code & Model</a></li>
                  <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/2008.01065">
                  <papertitle>Memory-augmented Dense Predictive Coding for Video Representation Learning.</papertitle>
                  </a>
                  <br>
                  Tengda Han,
                  <strong>Weidi Xie</strong>, Andrew Zisserman <br>
                  In: <em>European Conference on Computer Vision (ECCV) </em>, 2020
                  &nbsp <font color="red"><strong>(Spotlight Presentation)</strong></font> <br>
                  <a href="https://arxiv.org/abs/2008.01065">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/research/DPC/">Project Page</a> |
                  <a href="https://tengdahan.github.io">Code & Model</a></li>
                  <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/2002.07793">
                  <papertitle>MAST: A Memory-Augmented Self-Supervised Tracker.</papertitle>
                  </a>
                  <br>
                  Zihang Lai,
                  Erika Lu,
                  <strong>Weidi Xie</strong> <br>
                  In: <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020<br>
                  <a href="https://arxiv.org/abs/2002.07793">Arxiv</a> |
                  <a href="https://zlai0.github.io/MAST/">Project Page</a> |
                  <a href="https://github.com/zlai0/MAST">Code & Model</a></li>
                  <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/2004.14368">
                  <papertitle>VGG-Sound: A Large-Scale Audio-Visual Dataset.</papertitle>
                  </a>
                  <br>
                  Honglie Chen,
                  <strong>Weidi Xie</strong>,
                  Andrea Vedaldi,
                  Andrew Zisserman <br>
                  In: <em>International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2020<br>
                  <a href="https://arxiv.org/abs/2004.14368">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2020/Chen20/chen20.pdf">PDF</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/data/vggsound/">Project Page</a> |
                  <a href="https://github.com/hche11/VGGSound">Code & Model</a> </li>
                  <p> </p>

                  <li>
                  <a href="https://ieeexplore.ieee.org/document/8999615">
                  <papertitle>Low-Memory CNNs Enabling Real-Time Ultrasound Segmentation Towards Mobile Deployment.</papertitle>
                  </a>
                  <br>
                  Sagar Vaze, <strong>Weidi Xie</strong>, Ana Namburete. <br>
                  In: <em>IEEE Journal of Biomedical and Health Informatics</em>, 2020. (Impact Factor: ~6)<br>
                  <a href="https://sgvaze.github.io/pages/lightweight_unets.html">Project Page</a>  |
                  <a href="https://github.com/sgvaze/lightweight_unet">Code</a></li>
                  <p> </p>

                  <li>
                  <a href="https://www.sciencedirect.com/science/article/pii/S0885230819302712">
                  <papertitle>VoxCeleb: Large-scale Speaker Verification in the Wild.</papertitle>
                  </a>
                  <br>
                  Arsha Nagrani*, Joon Son Chung*, <strong>Weidi Xie*</strong>,
                  Andrew Zisserman.  (* indicates equal contribution)<br>
                  In: <em>Computer Speech & Language</em>, 2020. (Impact Factor: ~1.8)<br></li>
                  <p> </p>
                </ol>


                <heading>2019</heading>
                <ol>
                  <li>
                  <a href="https://arxiv.org/pdf/1912.02522.pdf">
                  <papertitle>VoxSRC 2019: The first VoxCeleb Speaker Recognition Challenge.</papertitle>
                  </a>
                  <br>
                  Joon Son Chung, Arsha Nagrani,
                  Ernesto Coto,
                  <strong>Weidi Xie</strong>,
                  Mitchell McLaren, Douglas A Reynolds,
                  Andrew Zisserman.<br>
                  <a href="https://arxiv.org/pdf/1912.02522.pdf">Tech Report</a></li>
                  <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/1909.04656">
                  <papertitle>Video Representation Learning by Dense Predictive Coding.</papertitle>
                  </a>
                  <br> Tengda Han,
                  <strong>Weidi Xie</strong>,
                  Andrew Zisserman<br>
                  In: <em>1st International Workshop on Large-scale Holistic Video Understanding, ICCV</em>, 2019.
                  &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
                  <a href="https://arxiv.org/abs/1909.04656">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/research/DPC/">Project Page</a> |
                  <a href="https://github.com/TengdaHan/DPC">Code</a> </li>
                  <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/1905.00875">
                  <papertitle>Self-supervised Learning for Video Correspondence Flow.</papertitle>
                  </a>
                  <br> Zihang Lai,
                  <strong>Weidi Xie</strong> <br>
                  In: <em>British Machine Vision Conference (BMVC)</em>, 2019.
                  &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
                  <a href="https://arxiv.org/abs/1905.00875">Arxiv</a> |
                  <a href="https://zlai0.github.io/CorrFlow/">Project Page</a> </li>
                  <p> </p>

                  <li>
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2019/Chen19/chen19.pdf">
                  <papertitle>AutoCorrect: Deep Inductive Alignment of Noisy Geometric Annotations.</papertitle>
                  </a>
                  <br> Honglie Chen,
                  <strong>Weidi Xie</strong>,
                  Andrea Vedaldi,
                  Andrew Zisserman. <br>
                  In: <em>British Machine Vision Conference (BMVC)</em>, 2019.
                  &nbsp <font color="red"><strong>(Spotlight Presentation)</strong></font> <br>
                  <a href="https://arxiv.org/abs/1908.05263">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2019/Chen19/chen19.pdf">PDF</a> </li>
                  <p> </p>

                  <li>
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2019/xu19/xu19.pdf">
                  <papertitle>Geometry-Aware Corner Network for Video Object Detection from Static Cameras.</papertitle>
                  </a>
                  <br> Dan Xu,
                  <strong>Weidi Xie</strong>,
                  Andrew Zisserman. <br>
                  In: <em>British Machine Vision Conference (BMVC)</em>, 2019.
                  &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
                  <a href="https://arxiv.org/abs/1909.03140">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2019/xu19/xu19.pdf">PDF</a> </li>
                  <p> </p>

                  <li>
                  <a href="https://arxiv.org/abs/1902.10107">
                  <papertitle>Utterance-level Aggregation for Speaker Recognition in the Wild.</papertitle>
                  </a>
                  <br>
                  <strong>Weidi Xie</strong>,
                  Arsha Nagrani, Joon Son Chung, Andrew Zisserman. <br>
                  In: <em>International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2019.
                  &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> <br>
                  <a href="https://arxiv.org/abs/1902.10107">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/research/speakerID/">Project Page</a> |
                  <a href="https://github.com/WeidiXie/VGG-Speaker-Recognition">Code & Model</a></li>
                  <p> </p>
                </ol>


                <heading>2018</heading>
                <ol>
                  <li>
                  <a href="https://www.robots.ox.ac.uk/~vgg/publications/2018/Xie18a/xie18a.pdf">
                  <papertitle>Comparator Networks.</papertitle>
                  </a>
                  <br>
                  <strong>Weidi Xie</strong>, Li Shen, Andrew Zisserman
                  <br>
                  In: <em>European Conference on Computer Vision (ECCV)</em>, 2018.
                  <br>
                  <a href="https://arxiv.org/abs/1807.11440">Arxiv</a> |
                  <a href="https://www.robots.ox.ac.uk/~vgg/publications/2018/Xie18a/xie18a.pdf">PDF</a></li>
                  <p> </p>

                  <li>
                  <a href="https://www.robots.ox.ac.uk/~vgg/publications/2018/Xie18b/xie18b.pdf">
                  <papertitle>Multicolumn Networks on Face Recognition.</papertitle>
                  </a>
                  <br>
                  <strong>Weidi Xie</strong>, Andrew Zisserman
                  <br>
                  In: <em>British Machine Vision Conference (BMVC)</em>, 2018.
                  <br>
                  <a href="https://arxiv.org/abs/1807.09192">Arxiv</a> |
                  <a href="https://www.robots.ox.ac.uk/~vgg/publications/2018/Xie18b/xie18b.pdf">PDF</a> |
                  <a href="https://github.com/WeidiXie/multicoumn_network">Code & Model</a> |
                  <a href="data/XieBMVC2018.bib">Bibtex</a></li>
                  <p> </p>

                  <li>
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2018/Lu18/lu18.pdf">
                  <papertitle>Class-Agnostic Counting.</papertitle>
                  </a>
                  <br>
                  Erika Lu, <strong>Weidi Xie</strong>, Andrew Zisserman
                  <br>
                  In: <em>Asian Conference on Computer Vision (ACCV)</em>, 2018.
                  <br>
                  <a href="https://arxiv.org/abs/1811.00472">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/research/class-agnostic-counting/">Project Page</a> |
                  <a href="data/XieBMVC2018.bib">Bibtex</a></li>
                  <p> </p>

                  <li>
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2018/Cao18/cao18.pdf">
                  <papertitle>VGGFace2: A Dataset for Recognising Faces Across Pose and Age.</papertitle>
                  </a>
                  <br>
                  Qiong Cao, Li Shen, <strong>Weidi Xie</strong>, Omkar M. Parkhi and Andrew Zisserman
                  <br>
                  In: <em>IEEE International Conference on Automatic Face and Gesture Recognition (F&G)</em>, 2018.
                  &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                  <br>
                  <a href="https://arxiv.org/abs/1710.08092">Arxiv</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2018/Cao18/cao18.pdf">PDF</a> |
                  <a href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/">Project Page</a> |
                  <a href="data/CaoFG2018.bib">Bibtex</a></li>
                  <p> </p>

                  <li>
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518302998">
                  <papertitle>Omega-Net: Fully Automatic, Multi-View Cardiac MR Detection, Orientation, and Segmentation with Deep Neural Networks.</papertitle>
                  </a>
                  <br>
                  <strong>Weidi Xie*, Davis M. Vigneault*</strong>, Carolyn Y. Ho, David A. Bluemke and J. Alison Noble (*joint first author)
                  <br>
                  In: <em>Medical Image Analysis, Volume 48, Pages 95, August 2018. (Impact Factor: ~14)</em>
                  <br>
                  <a href="https://arxiv.org/abs/1711.01094">Arxiv</a> |
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518302998">Paper</a></li>
                  <p> </p>

                  <li>
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518301920">
                  <papertitle>VP-Nets: Efficient Automatic Localization of Key Brain Structures in 3D Fetal Neurosonography.</papertitle>
                  </a>
                  <br>
                  Ruobing Huang, <strong>Weidi Xie</strong> and J. Alison Noble
                  <br>
                  In: <em>Medical Image Analysis, Volume 47, Pages 127, July 2018. (Impact Factor: ~14)</em>
                  <br>
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518301920">Paper</a></li>
                  <p> </p>

                  <li>
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518300306">
                  <papertitle>Fully-Automated Alignment of 3D Fetal Brain Ultrasound to a Canonical Reference Space Using Multi-task Learning.</papertitle>
                  </a>
                  <br>
                  <strong>Weidi Xie*, Ana I.L. Namburete*</strong>,   Mohammad Yaqub,
                  Andrew Zisserman and J. Alison Noble (*joint first author)
                  <br>
                  In: <em>Medical Image Analysis, Volume 46, Pages 1, May 2018. (Impact Factor: ~14)</em>
                  <br>
                  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518300306">Paper</a></li>
                  <p> </p>
                </ol>

                <heading>2017</heading>
                <ol>
                  <li>
                  <a href="https://link.springer.com/chapter/10.1007/978-3-319-59448-4_18">
                  <papertitle>Feature Tracking Cardiac Magnetic Resonance via Deep Learning and Spline Optimization.</papertitle>
                  </a>
                  <br>
                  Davis M. Vigneaulta, <strong>Weidi Xie</strong>, David A. Bluemke and J. Alison Noble
                  <br>
                  In: <em>Functional Imaging and Modelling of the Heart (FIMH)</em>, 2017.
                  &nbsp <font color="red"><strong>(Best Poster Award)</strong></font>
                  <br>
                  <a href="https://arxiv.org/abs/1704.03660">Arxiv</a> |
                  <a href="https://link.springer.com/chapter/10.1007/978-3-319-59448-4_18">Paper</a></li>
                  <p> </p>

                  <li>
                  <a href="https://link.springer.com/chapter/10.1007%2F978-3-319-67561-9_8">
                  <papertitle>Robust Regression of Brain Maturation from 3D Fetal Neurosonography using CRNs.</papertitle>
                  </a>
                  <br>
                  Ana I.L. Namburete, <strong>Weidi Xie</strong> and J. Alison Noble
                  <br>
                  In: <em>MICCAI Workshop on Fetal and InFant Image analysis (FIFI)</em>, 2017.
                  &nbsp <font color="red"><strong>(Best Paper Award)</strong></font>
                  <br>
                  <a href="https://www.dropbox.com/s/ypyita3gabr2cs4/3d_brain_age.pdf?dl=0">Paper</a></li>
                  <p> </p>
                </ol>

                <heading>2016</heading>
                <ol>
                  <li>
                  <a href="https://www.tandfonline.com/doi/full/10.1080/21681163.2016.1149104">
                  <papertitle>Microscopy Cell Counting and Detection with Fully Convolutional Regression Networks.</papertitle>
                  </a>
                  <br>
                  <strong>Weidi Xie</strong>, J. Alison Noble and Andrew Zisserman
                  <br>
                  In: <em>MICCAI 1st Deep Learning Workshop</em>, 2015.
                  <br>
                  In: <em>Computer Methods in Biomechanics and Biomedical Engineering: Imaging & Visualization</em>, 2016.
                  &nbsp <font color="red"><strong>(Biannual Best Journal Article)</strong></font>
                  <br>
                  <a href="http://www.robots.ox.ac.uk/~vgg/publications/2016/Xie16/xie16.pdf">Paper</a> |
                  <a href="https://github.com/WeidiXie/cell_counting_v2">Code</a> |
                  <a href="https://think.taylorandfrancis.com/journal-prize-computer-methods-in-biomechanics-and-biomedical-engineering-imaging-visualization-best-paper-award/">Award</a></li>
                  <p> </p>
                </ol>
              </td>
            </tr>
            </table>
                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                      <td>
                        <br>
                        <p align="center">
                          <font size="2">
                            Based on a template by <a href="https://jonbarron.info">Jon Barron</a>
                            </font>
                        </p>
                      </td>
                    </tr>
                  </table>
                  </td>
              </tr>
            </table>
          </body>
          </html>